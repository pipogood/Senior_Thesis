{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWT & STFT + CNN Model with Unicorn Hybrid Black dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand0_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand1_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand2_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand3_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand4_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand5_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand6_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand7_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 189249  =      0.000 ...   756.996 secs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>October 01, 2023  18:29:02 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>11 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>8 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>hand1_new.edf</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:18:37 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawEDF | hand1_new.edf, 8 x 279250 (1117.0 s), ~17.1 MB, data loaded>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne.datasets import eegbci\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.channels import make_standard_montage\n",
    "\n",
    "raw_each = [0] * 8\n",
    "\n",
    "for i in range(0,8):\n",
    "    raw_each[i] = mne.io.read_raw_edf(\"C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand\"+ str(i) +\"_new.edf\",preload = True)\n",
    "\n",
    "# raw_edf = mne.concatenate_raws(raw_each)\n",
    "# raw_edf = mne.concatenate_raws([raw_each[1], raw_each[3], raw_each[4]])\n",
    "# raw_edf = mne.concatenate_raws([raw_each[0], raw_each[5], raw_each[6]])\n",
    "\n",
    "raw_edf = mne.concatenate_raws([raw_each[3]])\n",
    "\n",
    "# raw_edf = mne.io.read_raw_edf(\"C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\MI_execution.edf\", preload=True)\n",
    "\n",
    "eegbci.standardize(raw_edf)  # set channel names\n",
    "montage = make_standard_montage(\"standard_1005\")\n",
    "raw_edf.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_edf.plot(scalings = 100, start= 45,  duration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History,ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "history = History()\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mne.decoding import CSP\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit,StratifiedKFold ,cross_val_score, cross_val_predict\n",
    "from ssqueezepy import ssq_cwt, ssq_stft\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 6 - 32 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 20 (effective, after forward-backward)\n",
      "- Cutoffs at 6.00, 32.00 Hz: -6.02, -6.02 dB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['OVTK_GDF_Cross_On_Screen', 'OVTK_GDF_End_Of_Session', 'OVTK_GDF_End_Of_Trial', 'OVTK_GDF_Feedback_Continuous', 'OVTK_GDF_Incorrect', 'OVTK_GDF_Left', 'OVTK_GDF_Right', 'OVTK_GDF_Start_Of_Trial', 'OVTK_GDF_Tongue', 'OVTK_GDF_Up', 'OVTK_StimulationId_BaselineStart', 'OVTK_StimulationId_BaselineStop', 'OVTK_StimulationId_Beep', 'OVTK_StimulationId_ExperimentStart', 'OVTK_StimulationId_Train']\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Not setting metadata\n",
      "608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 608 events and 1001 original time points ...\n",
      "2 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "eeg1 = raw_edf.copy().filter(l_freq=6.0, h_freq=32.0, method = 'iir', iir_params= {\"order\": 5, \"ftype\":'butter'})\n",
    "# eeg1 = raw_edf.copy().filter(l_freq=0.075, h_freq=3.0, method = 'fir')\n",
    "eeg1 = eeg1.copy().set_eeg_reference(ref_channels=\"average\")\n",
    "\n",
    "eeg1= eeg1.pick([\"Fz\",\"C3\", \"Cz\", \"C4\",\"Pz\",'PO7','PO8'])\n",
    "\n",
    "events, event_dict = mne.events_from_annotations(eeg1)\n",
    "combine_epochs = mne.Epochs(eeg1, events, \n",
    "        tmin= -1.0,     # init timestamp of epoch (0 means trigger timestamp same as event start)\n",
    "        tmax= 3.0,    # final timestamp (10 means set epoch duration 10 second)\n",
    "        event_id=event_dict,\n",
    "        preload = True,\n",
    "        event_repeated='drop',\n",
    "        baseline=(-0.2, 0)\n",
    "    )\n",
    "\n",
    "combine_epochs = combine_epochs.copy().crop(tmin=0.0, tmax=2.0)\n",
    "\n",
    "component_num = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>OVTK_GDF_Cross_On_Screen: 3<br/>OVTK_GDF_End_Of_Session: 1<br/>OVTK_GDF_End_Of_Trial: 120<br/>OVTK_GDF_Feedback_Continuous: 120<br/>OVTK_GDF_Left: 30<br/>OVTK_GDF_Right: 30<br/>OVTK_GDF_Start_Of_Trial: 120<br/>OVTK_GDF_Tongue: 30<br/>OVTK_GDF_Up: 30<br/>OVTK_StimulationId_BaselineStart: 1<br/>OVTK_StimulationId_BaselineStop: 1<br/>OVTK_StimulationId_Beep: 120<br/>OVTK_StimulationId_ExperimentStart: 0<br/>OVTK_StimulationId_Train: 0</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 2.000 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 s</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  606 events (all good), 0 – 2 s, baseline -0.2 – 0 s (baseline period was cropped after baseline correction), ~16.2 MB, data loaded,\n",
       " 'OVTK_GDF_Cross_On_Screen': 3\n",
       " 'OVTK_GDF_End_Of_Session': 1\n",
       " 'OVTK_GDF_End_Of_Trial': 120\n",
       " 'OVTK_GDF_Feedback_Continuous': 120\n",
       " 'OVTK_GDF_Left': 30\n",
       " 'OVTK_GDF_Right': 30\n",
       " 'OVTK_GDF_Start_Of_Trial': 120\n",
       " 'OVTK_GDF_Tongue': 30\n",
       " 'OVTK_GDF_Up': 30\n",
       " 'OVTK_StimulationId_BaselineStart': 1\n",
       " and 4 more events ...>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = combine_epochs['OVTK_GDF_Left'].to_data_frame()\n",
    "df_right = combine_epochs['OVTK_GDF_Right'].to_data_frame()\n",
    "df_up = combine_epochs['OVTK_GDF_Up'].to_data_frame()\n",
    "df_tongue = combine_epochs['OVTK_GDF_Tongue'].to_data_frame()\n",
    "df_left =df_left.iloc[:, -7:]\n",
    "df_right =df_right.iloc[:, -7:]\n",
    "df_up =df_up.iloc[:, -7:]\n",
    "df_tongue =df_tongue.iloc[:, -7:]\n",
    "\n",
    "# # Plot histograms for all columns in the DataFrame using Seaborn\n",
    "# fig, ax = plt.subplots(1, len(df_left.columns),sharey=True, figsize=(10 * len(df_left.columns), 10))\n",
    "# for i, column in enumerate(df_left.columns):\n",
    "#     ax[i] = sns.histplot(df_left[column], kde=False, ax=ax[i], color= 'orange')\n",
    "#     ax[i] = sns.histplot(df_right[column], kde=False, ax=ax[i], color= 'blue')\n",
    "#     ax[i] = sns.histplot(df_up[column], kde=False, ax=ax[i], color= 'green')\n",
    "#     ax[i] = sns.histplot(df_tongue[column], kde=False, ax=ax[i], color= 'pink')\n",
    "#     ax[i].set_xlabel(column,  fontsize=30)\n",
    "#     ax[i].set_ylabel('Frequency',  fontsize=30)\n",
    "#     ax[i].tick_params(axis='both', labelsize=30)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Example DataFrame (replace this with your actual DataFrame)\n",
    "# data = {\n",
    "#     'column1': [1, 2, 3, 4, 5],\n",
    "#     'column2': [2, 3, 4, 5, 6],\n",
    "#     'column3': [3, 4, 5, 6, 7],\n",
    "#     'column4': [4, 5, 6, 7, 8],\n",
    "#     'column5': [5, 6, 7, 8, 9]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Select the last three columns\n",
    "# last_three_columns = df.iloc[:, -3:]\n",
    "\n",
    "# # Plot histograms for the last three columns using Seaborn in a horizontal line\n",
    "# fig, ax = plt.subplots(1, len(last_three_columns.columns), sharey=True, figsize=(6 * len(last_three_columns.columns), 6))\n",
    "# for i, column in enumerate(last_three_columns.columns):\n",
    "#     sns.histplot(last_three_columns[column], kde=False, bins=10, ax=ax[i])\n",
    "#     ax[i].set_xlabel(column)\n",
    "#     ax[i].set_ylabel('Frequency')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY FBCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_fre = [6, 10, 14, 18, 22, 26]\n",
    "# high_fre = [12, 16, 20, 24, 28, 32]\n",
    "\n",
    "# shape = combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue'].get_data().shape\n",
    "\n",
    "# train_data = np.ndarray(shape= (6,shape[0],shape[1],shape[2]))\n",
    "\n",
    "# # FB_data = np.ndarray(shape= (6,shape[0],shape[1],shape[2]))\n",
    "# FB_data = np.ndarray(shape= (6,shape[0],shape[1]))\n",
    "\n",
    "\n",
    "# for i in range(0,6):\n",
    "#     combine_epochs = combine_epochs.filter(l_freq=low_fre[i], h_freq=high_fre[i], method = 'iir', iir_params= {\"order\": 5, \"ftype\":'butter'}, verbose = False)\n",
    "#     train_data[i] = combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue'].get_data()\n",
    "    \n",
    "#     # csp = CSP(n_components=component_num, reg=None, log=None, transform_into='csp_space')\n",
    "#     csp = CSP(n_components=component_num, reg=None, log=None)\n",
    "#     csp.fit(train_data[i], labels)\n",
    "\n",
    "#     with open('trained_FBCSP_model'+str(i)+'.pkl', 'wb') as file:\n",
    "#         pickle.dump(csp, file)\n",
    "\n",
    "# for j in range(0,6):\n",
    "#     with open('trained_FBCSP_model'+str(j)+'.pkl', 'rb') as file:\n",
    "#         trained_csp = pickle.load(file)\n",
    "\n",
    "#     FB_data[j] = trained_csp.transform(train_data[j])\n",
    "\n",
    "# FB_data = np.concatenate(FB_data, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lda3 = LinearDiscriminantAnalysis()\n",
    "# # lda3.fit(new_data, labels)\n",
    "# # with open('trained_lda3_model.pkl', 'wb') as file:\n",
    "# #     pickle.dump(lda3, file)\n",
    "\n",
    "# with open('trained_lda3_model.pkl', 'rb') as file:\n",
    "#     trained_lda3 = pickle.load(file)\n",
    "\n",
    "\n",
    "# # score = cross_val_score(trained_lda3, new_data, labels, cv= 10)\n",
    "# # lda_predicted = cross_val_predict(trained_lda3, new_data, labels, cv= 10)\n",
    "# # conf_matrix = confusion_matrix(labels, lda_predicted)\n",
    "# # print(\"LDA only classification scores\", np.mean(score))\n",
    "# # print(conf_matrix)\n",
    "\n",
    "# score = trained_lda3.score(new_data, labels)\n",
    "# lda_predicted = trained_lda3.predict(new_data)\n",
    "# conf_matrix = confusion_matrix(labels, lda_predicted)\n",
    "# print(\"LDA only classification scores\", score)\n",
    "# print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ica = ICA(n_components=8, max_iter=10000, random_state=97)\n",
    "# ica.fit(train_data)\n",
    "# ica.plot_sources(train_data)\n",
    "# with open('trained_ica_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(ica, file)\n",
    "\n",
    "# with open('trained_ica_model.pkl', 'rb') as file:\n",
    "#     trained_ica = pickle.load(file)\n",
    "# ica_data = trained_ica.get_sources(train_data)\n",
    "# train_data = ica_data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OVTK_GDF_Cross_On_Screen': 1,\n",
       " 'OVTK_GDF_End_Of_Session': 2,\n",
       " 'OVTK_GDF_End_Of_Trial': 3,\n",
       " 'OVTK_GDF_Feedback_Continuous': 4,\n",
       " 'OVTK_GDF_Left': 6,\n",
       " 'OVTK_GDF_Right': 7,\n",
       " 'OVTK_GDF_Start_Of_Trial': 8,\n",
       " 'OVTK_GDF_Tongue': 9,\n",
       " 'OVTK_GDF_Up': 10,\n",
       " 'OVTK_StimulationId_BaselineStart': 11,\n",
       " 'OVTK_StimulationId_BaselineStop': 12,\n",
       " 'OVTK_StimulationId_Beep': 13,\n",
       " 'OVTK_StimulationId_ExperimentStart': 14,\n",
       " 'OVTK_StimulationId_Train': 15}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_epochs.event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSP -> CWT -> CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare Labels and Train data\n",
    "# labels = combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue'].events[:,2]\n",
    "# for i in range(0,len(labels)):\n",
    "#     if labels[i] > 7:\n",
    "#         labels[i] = labels[i] - 1\n",
    "#     # if labels[i] < 7:\n",
    "#     #     labels[i] = labels[i] + 1\n",
    "# train_data = combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue'].get_data()\n",
    "\n",
    "################ 3 Classes #######################\n",
    "labels = combine_epochs['OVTK_GDF_Right','OVTK_GDF_Tongue'].events[:,2]\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] > 7:\n",
    "        labels[i] = labels[i] - 1\n",
    "    # if labels[i] <= 7:\n",
    "    #     labels[i] = labels[i] + 1\n",
    "train_data = combine_epochs['OVTK_GDF_Right','OVTK_GDF_Tongue'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 7, 8, 7, 8, 7, 8, 7, 8, 7, 7, 7, 8, 8, 7, 8, 7, 8, 8, 7, 8,\n",
       "       7, 8, 7, 7, 8, 7, 8, 8, 8, 7, 8, 7, 8, 8, 7, 8, 7, 8, 7, 8, 7, 8,\n",
       "       7, 7, 7, 7, 8, 7, 8, 7, 8, 8, 7, 8, 8, 7, 7, 8])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csp = CSP(n_components=component_num, reg=None, log=None, transform_into='csp_space')\n",
    "# csp.fit(train_data, labels)\n",
    "\n",
    "# with open('trained_csp_2class_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(csp, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 7, 501)\n"
     ]
    }
   ],
   "source": [
    "with open('trained_csp_2class_model.pkl', 'rb') as file:\n",
    "    trained_csp = pickle.load(file)\n",
    "\n",
    "new_data = trained_csp.transform(train_data)\n",
    "print(new_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try csp+lda trined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA only classification scores 0.7833333333333333\n",
      "[[23  7]\n",
      " [ 6 24]]\n"
     ]
    }
   ],
   "source": [
    "# csp2 = CSP(n_components=7, reg=None, log=None)\n",
    "# csp2.fit(train_data, labels)\n",
    "# with open('trained_csp2_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(csp2, file)\n",
    "\n",
    "with open('trained_csp2_model.pkl', 'rb') as file:\n",
    "    trained_csp2 = pickle.load(file)\n",
    "new_data2 = trained_csp2.transform(train_data)\n",
    "\n",
    "# lda2 = LinearDiscriminantAnalysis()\n",
    "# lda2.fit(new_data2, labels)\n",
    "# with open('trained_lda_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(lda2, file)\n",
    "\n",
    "with open('trained_lda_model.pkl', 'rb') as file:\n",
    "    trained_lda = pickle.load(file)\n",
    "\n",
    "    \n",
    "score = cross_val_score(trained_lda,new_data2, labels, cv= 10)\n",
    "lda_predicted = cross_val_predict(trained_lda, new_data2, labels, cv=10)\n",
    "conf_matrix = confusion_matrix(labels, lda_predicted)\n",
    "print(\"LDA only classification scores\", np.mean(score))\n",
    "print(conf_matrix)\n",
    "\n",
    "# score = trained_lda.score(new_data2, labels)\n",
    "# lda_predicted = trained_lda.predict(new_data2)\n",
    "# conf_matrix = confusion_matrix(labels, lda_predicted)\n",
    "# print(\"LDA only classification scores\", score)\n",
    "# print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 7, 501)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot topographic patterns of components. The patterns explain how the measured data was generated from the neural sources (a.k.a. the forward model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_csp.plot_patterns(combine_epochs.info, ch_type=\"eeg\", units=\"Patterns (AU)\", size=1.5, vlim=(-5e6, 5e6))\n",
    "# print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_events = combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue']\n",
    "# csp_epochs = mne.EpochsArray(new_data, selected_events.info, events=selected_events.events, event_id= selected_events.event_id)\n",
    "# channel_mapping = {\n",
    "#     'Fz': 'csp1',\n",
    "#     'C3': 'csp2',\n",
    "#     'Cz': 'csp3',\n",
    "#     'C4': 'csp4',\n",
    "#     'Pz': 'csp5',\n",
    "#     'PO7': 'csp6',\n",
    "#     'PO8': 'csp7'\n",
    "# }\n",
    "# csp_epochs.rename_channels(channel_mapping)\n",
    "\n",
    "# csp_left_df = csp_epochs['OVTK_GDF_Left'].to_data_frame()\n",
    "# csp_right_df = csp_epochs['OVTK_GDF_Right'].to_data_frame()\n",
    "# csp_up_df = csp_epochs['OVTK_GDF_Up'].to_data_frame()\n",
    "# csp_tongue_df = csp_epochs['OVTK_GDF_Tongue'].to_data_frame()\n",
    "\n",
    "# csp_left_df =csp_left_df.iloc[:, -7:]\n",
    "# csp_right_df =csp_right_df.iloc[:, -7:]\n",
    "# csp_up_df =csp_up_df.iloc[:, -7:]\n",
    "# csp_tongue_df =csp_tongue_df.iloc[:, -7:]\n",
    "\n",
    "# # Plot histograms for all columns in the DataFrame using Seaborn\n",
    "# fig, ax = plt.subplots(1, len(csp_left_df.columns),sharey=True, figsize=(10 * len(csp_left_df.columns), 10))\n",
    "# for i, column in enumerate(csp_left_df.columns):\n",
    "#     ax[i] = sns.histplot(csp_left_df[column], kde=False, ax=ax[i], color= 'orange')\n",
    "#     ax[i] = sns.histplot(csp_right_df[column], kde=False, ax=ax[i], color= 'blue')\n",
    "#     ax[i] = sns.histplot(csp_up_df[column], kde=False, ax=ax[i], color= 'green')\n",
    "#     ax[i] = sns.histplot(csp_tongue_df[column], kde=False, ax=ax[i], color= 'pink')\n",
    "#     ax[i].set_xlabel(column,  fontsize=30)\n",
    "#     # ax[i].set_xlim(-1e7, 1e7)\n",
    "#     ax[i].set_ylabel('Frequency',  fontsize=30)\n",
    "#     ax[i].tick_params(axis='both', labelsize=30)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ssqueezepy import ssq_cwt, ssq_stft\n",
    "\n",
    "# n_fft = 256  # Number of DFT points\n",
    "# hop_length = int(n_fft * 0.03)  # 97% overlapping\n",
    "# win_length = int(n_fft * 0.5)   # 0.5 seconds window length\n",
    "# window = 'hamming' \n",
    "# train_size = len(labels)\n",
    "# train_data_stft = np.ndarray(shape=(train_size,component_num, 129, 72))\n",
    "\n",
    "\n",
    "# # _,coeff, *_ = ssq_stft(new_data[0,:], n_fft=n_fft, hop_len=hop_length, win_len=win_length, window=window)\n",
    "# for i in range(0,train_size):\n",
    "#     _,coeff, *_ = ssq_stft(new_data[i,:], n_fft=n_fft, hop_len=hop_length, win_len=win_length, window=window)\n",
    "#     train_data_stft[i, :, :, :] = abs(coeff)\n",
    "\n",
    "# print(np.shape(train_data_stft))\n",
    "\n",
    "# # Stack array and convert to image\n",
    "# train_stft_stack = np.ndarray(shape=(train_size, train_data_stft.shape[2],train_data_stft.shape[3]*component_num))\n",
    "\n",
    "# for jj in range(0,train_data_stft.shape[0]):\n",
    "#     train_stft_stack[jj] = np.concatenate(train_data_stft[jj], axis = 1)\n",
    "#     # train_stft_stack[jj] = np.vstack((train_data_stft[jj,0,:,:], train_data_stft[jj,1,:,:], train_data_stft[jj,2,:,:], train_data_stft[jj,3,:,:], train_data_stft[jj,4,:,:], train_data_stft[jj,5,:,:], train_data_stft[jj,6,:,:]))\n",
    "\n",
    "# print(np.shape(train_stft_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 501, 7)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "(60, 30, 501, 7)\n",
      "(60, 210, 501)\n"
     ]
    }
   ],
   "source": [
    "FB = 1\n",
    "train_cwt = np.ndarray(shape=(new_data.shape[0], new_data.shape[2], component_num*FB))\n",
    "for jj in range(0, new_data.shape[0]):\n",
    "    train_cwt[jj] = new_data[jj].T\n",
    "print(np.shape(train_cwt))\n",
    "\n",
    "scales = range(1,31)\n",
    "\n",
    "waveletname = 'morl'\n",
    "train_size = len(labels)\n",
    "train_data_cwt = np.ndarray(shape=(train_size, len(scales), new_data.shape[2], component_num*FB))\n",
    "\n",
    "for ii in range(0,train_size):\n",
    "    if ii % 40 == 0:\n",
    "        print(ii)\n",
    "    for jj in range(0,component_num*FB):\n",
    "        signal = train_cwt[ii, :, jj]\n",
    "        coeff, _ = pywt.cwt(signal, scales, waveletname, 1)\n",
    "        coeff_ = coeff[:,:new_data.shape[2]]  #crop 227 sample for each channel\n",
    "        train_data_cwt[ii, :, :, jj] = coeff_\n",
    "print(np.shape(train_data_cwt))\n",
    "\n",
    "train_cwt_stack = np.ndarray(shape=(train_size, len(scales)*component_num*FB, new_data.shape[2]))\n",
    "\n",
    "# train_cwt_stack = np.ndarray(shape=(train_size , new_data.shape[2], len(scales)*component_num*FB))\n",
    "\n",
    "\n",
    "for jj in range(0,train_data_cwt.shape[0]):\n",
    "    # train_cwt_stack[jj] = np.concatenate(train_data_cwt[jj], axis = 1)\n",
    "    train_cwt_stack[jj] = np.vstack((train_data_cwt[jj,:,:,0], train_data_cwt[jj,:,:,1], train_data_cwt[jj,:,:,2], train_data_cwt[jj,:,:,3], train_data_cwt[jj,:,:,4], train_data_cwt[jj,:,:,5], train_data_cwt[jj,:,:,6]))\n",
    "\n",
    "print(np.shape(train_cwt_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# reshaped_data = train_cwt_stack.reshape((train_cwt_stack.shape[0], -1))\n",
    "# scaled_data = scaler.fit_transform(reshaped_data)\n",
    "# scaled_data_3d = scaled_data.reshape(train_cwt_stack.shape)\n",
    "# print(scaled_data_3d.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
