{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWT & STFT + CNN Model with BCI_competitionIII dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand0_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand1_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand2_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand3_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n",
      "Extracting EDF parameters from C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand4_new.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 279249  =      0.000 ...  1116.996 secs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>October 01, 2023  19:53:00 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>11 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>8 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>hand3_new.edf</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:18:37 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawEDF | hand3_new.edf, 8 x 279250 (1117.0 s), ~17.1 MB, data loaded>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne.datasets import eegbci\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.channels import make_standard_montage\n",
    "\n",
    "raw_each = [0] * 5\n",
    "\n",
    "for i in range(0,5):\n",
    "    raw_each[i] = mne.io.read_raw_edf(\"C:\\git\\Senior_Thesis\\DataSet\\Convert_data\\hand\"+ str(i) +\"_new.edf\",preload = True)\n",
    "\n",
    "# raw_edf = mne.concatenate_raws(raw_each)\n",
    "raw_edf = mne.concatenate_raws([raw_each[3]])\n",
    "# raw_edf = raw_edf.copy().resample(62.5 ,npad=\"auto\")\n",
    "\n",
    "eegbci.standardize(raw_edf)  # set channel names\n",
    "montage = make_standard_montage(\"standard_1005\")\n",
    "raw_edf.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mne.decoding import CSP\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit,StratifiedKFold ,cross_val_score, cross_val_predict\n",
    "from ssqueezepy import ssq_cwt, ssq_stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 30 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 20 (effective, after forward-backward)\n",
      "- Cutoffs at 1.00, 30.00 Hz: -6.02, -6.02 dB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: ['OVTK_GDF_Cross_On_Screen', 'OVTK_GDF_End_Of_Session', 'OVTK_GDF_End_Of_Trial', 'OVTK_GDF_Feedback_Continuous', 'OVTK_GDF_Incorrect', 'OVTK_GDF_Left', 'OVTK_GDF_Right', 'OVTK_GDF_Start_Of_Trial', 'OVTK_GDF_Tongue', 'OVTK_GDF_Up', 'OVTK_StimulationId_BaselineStart', 'OVTK_StimulationId_BaselineStop', 'OVTK_StimulationId_Beep', 'OVTK_StimulationId_Train']\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Not setting metadata\n",
      "605 matching events found\n",
      "Setting baseline interval to [-5.0, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 605 events and 2501 original time points ...\n",
      "2 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "eeg1 = raw_edf.copy().filter(l_freq=1.0, h_freq=30.0, method = 'iir', iir_params= {\"order\": 5, \"ftype\":'butter'})\n",
    "# eeg1 = raw_edf.copy().filter(l_freq=0.075, h_freq=3.0, method = 'fir')\n",
    "eeg1 = eeg1.copy().set_eeg_reference(ref_channels=\"average\")\n",
    "\n",
    "eeg1= eeg1.pick([\"Fz\",\"C3\", \"Cz\", \"C4\",\"Pz\",'PO7','PO8'])\n",
    "# eeg1= eeg1.pick_channels([\"C3\", \"Cz\", \"C4\"])\n",
    "events, event_dict = mne.events_from_annotations(eeg1)\n",
    "combine_epochs = mne.Epochs(eeg1, events, \n",
    "        tmin=-5.0,     # init timestamp of epoch (0 means trigger timestamp same as event start)\n",
    "        tmax=5.0,    # final timestamp (10 means set epoch duration 10 second)\n",
    "        event_id=event_dict,\n",
    "        preload = True,\n",
    "        event_repeated='drop'\n",
    "    )\n",
    "\n",
    "combine_epochs = combine_epochs.copy().crop(tmin=0.0, tmax=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>OVTK_GDF_Cross_On_Screen: 1<br/>OVTK_GDF_End_Of_Session: 1<br/>OVTK_GDF_End_Of_Trial: 120<br/>OVTK_GDF_Feedback_Continuous: 120<br/>OVTK_GDF_Left: 30<br/>OVTK_GDF_Right: 30<br/>OVTK_GDF_Start_Of_Trial: 120<br/>OVTK_GDF_Tongue: 30<br/>OVTK_GDF_Up: 30<br/>OVTK_StimulationId_BaselineStart: 0<br/>OVTK_StimulationId_BaselineStop: 1<br/>OVTK_StimulationId_Beep: 120<br/>OVTK_StimulationId_Train: 0</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 4.000 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-5.000 – 0.000 s</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  603 events (all good), 0 – 4 s, baseline -5 – 0 s (baseline period was cropped after baseline correction), ~32.3 MB, data loaded,\n",
       " 'OVTK_GDF_Cross_On_Screen': 1\n",
       " 'OVTK_GDF_End_Of_Session': 1\n",
       " 'OVTK_GDF_End_Of_Trial': 120\n",
       " 'OVTK_GDF_Feedback_Continuous': 120\n",
       " 'OVTK_GDF_Left': 30\n",
       " 'OVTK_GDF_Right': 30\n",
       " 'OVTK_GDF_Start_Of_Trial': 120\n",
       " 'OVTK_GDF_Tongue': 30\n",
       " 'OVTK_GDF_Up': 30\n",
       " 'OVTK_StimulationId_BaselineStart': 0\n",
       " and 3 more events ...>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue'].get_data().shape[2]\n",
    "labels = combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue'].events[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(labels)):\n",
    "    if labels[i] > 7:\n",
    "        labels[i] = labels[i] - 1\n",
    "\n",
    "shape = np.shape(combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue'].get_data())\n",
    "train_data = combine_epochs['OVTK_GDF_Left','OVTK_GDF_Right','OVTK_GDF_Up','OVTK_GDF_Tongue'].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 7, 1001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.9 (2.2e-16 eps * 7 dim * 1.2e+15  max singular value)\n",
      "    Estimated rank (mag): 7\n",
      "    MAG: rank 7 computed from 7 data channels with 0 projectors\n",
      "Reducing data rank from 7 -> 7\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.9 (2.2e-16 eps * 7 dim * 1.2e+15  max singular value)\n",
      "    Estimated rank (mag): 7\n",
      "    MAG: rank 7 computed from 7 data channels with 0 projectors\n",
      "Reducing data rank from 7 -> 7\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.9 (2.2e-16 eps * 7 dim * 1.2e+15  max singular value)\n",
      "    Estimated rank (mag): 7\n",
      "    MAG: rank 7 computed from 7 data channels with 0 projectors\n",
      "Reducing data rank from 7 -> 7\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.1 (2.2e-16 eps * 7 dim * 1.3e+15  max singular value)\n",
      "    Estimated rank (mag): 7\n",
      "    MAG: rank 7 computed from 7 data channels with 0 projectors\n",
      "Reducing data rank from 7 -> 7\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from mne.decoding import CSP\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "csp = CSP(n_components=7, reg=None, log=None, norm_trace=False, transform_into='csp_space')\n",
    "# clf = Pipeline([(\"CSP\", csp), (\"LDA\", lda)])\n",
    "# scores = cross_val_score(clf, train_data, labels, cv=5, n_jobs=None)\n",
    "\n",
    "csp.fit(train_data, labels)\n",
    "new_data = csp.transform(train_data)\n",
    "\n",
    "# array_2d = csp_coeff.reshape(csp_coeff.shape[0], csp_coeff.shape[1]*csp_coeff.shape[2])\n",
    "# x_train, x_test, y_train, y_test = train_test_split(array_2d, labels, test_size=0.2, random_state=42)\n",
    "# lda.fit(x_train,y_train)\n",
    "# scores = lda.score(x_test, y_test)\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 7, 1001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ssqueezepy import ssq_cwt, ssq_stft\n",
    "\n",
    "# n_fft = 256  # Number of DFT points\n",
    "# hop_length = int(n_fft * 0.03)  # 97% overlapping\n",
    "# win_length = int(n_fft * 0.5)   # 0.5 seconds window length\n",
    "# window = 'hamming' \n",
    "# train_size = len(labels)\n",
    "# train_data_stft = np.ndarray(shape=(train_size, 129,143,7))\n",
    "\n",
    "\n",
    "# _,coeff, *_ = ssq_stft(new_data[0,:], n_fft=n_fft, hop_len=hop_length, win_len=win_length, window=window)\n",
    "# for i in range(0,train_size):\n",
    "#     _,coeff, *_ = ssq_stft(new_data[0,:], n_fft=n_fft, hop_len=hop_length, win_len=win_length, window=window)\n",
    "#     train_data_stft[i, :, :, :] = abs(coeff.reshape(coeff.shape[1],coeff.shape[2],coeff.shape[0]))\n",
    "\n",
    "# np.shape(train_data_stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pywt\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Sample image dimensions\n",
    "# def to_image(coeff):\n",
    "#     width = 37\n",
    "#     height = 7\n",
    "\n",
    "#     # Generate a sample 2D CWT array (replace this with your actual CWT coefficients)\n",
    "#     cwt_coefficients = abs(coeff)\n",
    "\n",
    "#     # Create an empty 3D array for the image (assuming RGB color channels)\n",
    "#     color_channels = 3\n",
    "#     image_3d = np.zeros((width, height, color_channels), dtype=np.uint8)\n",
    "\n",
    "#     # Map the CWT coefficients to color channels for visualization\n",
    "#     # You may need to adjust this mapping based on your specific data\n",
    "#     min_value = np.min(cwt_coefficients)\n",
    "#     max_value = np.max(cwt_coefficients)\n",
    "#     normalized_cwt = (cwt_coefficients - min_value) / (max_value - min_value)\n",
    "\n",
    "#     # Assign the CWT coefficients to the color channels\n",
    "#     image_3d[:, :, 0] = (normalized_cwt * 255).astype(np.uint8)  # Red channel\n",
    "#     image_3d[:, :, 1] = (normalized_cwt * 255).astype(np.uint8)  # Green channel\n",
    "#     image_3d[:, :, 2] = (normalized_cwt * 255).astype(np.uint8)  # Blue channel\n",
    "\n",
    "#     return image_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 7, 1001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 7, 1001)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "80\n",
      "(30, 1001) (30, 1001)\n"
     ]
    }
   ],
   "source": [
    "train_cwt = np.ndarray(shape=(120, 1001, 7))\n",
    "for jj in range(0, new_data.shape[0]):\n",
    "    train_cwt[jj] = new_data[jj].T\n",
    "print(np.shape(new_data))\n",
    "\n",
    "scales = range(1,31)\n",
    "\n",
    "waveletname = 'morl'\n",
    "train_size = len(labels)\n",
    "train_data_cwt = np.ndarray(shape=(train_size, 30, 1001, 7))\n",
    "\n",
    "for ii in range(0,train_size):\n",
    "    if ii % 40 == 0:\n",
    "        print(ii)\n",
    "    for jj in range(0,7):\n",
    "        signal = train_cwt[ii, :, jj]\n",
    "        coeff, _ = pywt.cwt(signal, scales, waveletname, 1)\n",
    "        coeff_ = coeff[:,:1001]  #crop 227 sample for each channel\n",
    "        train_data_cwt[ii, :, :, jj] = np.abs(coeff_)\n",
    "print(np.shape(coeff),np.shape(coeff_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 30, 1001, 7) (24, 30, 1001, 7) (96,) (24,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data_cwt, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "img_x = train_data_cwt.shape[1]\n",
    "img_y = train_data_cwt.shape[2]\n",
    "img_z = train_data_cwt.shape[3]\n",
    "num_classes = 4\n",
    "\n",
    "batch_size = 12\n",
    "epochs = 100\n",
    "print(np.shape(x_train), np.shape(x_test), np.shape(y_train), np.shape(y_test))\n",
    "\n",
    "# del train_data_cwt\n",
    "# del combine_epochs\n",
    "# plt.imshow(x_train[0,:,:,1], aspect='auto', cmap='turbo')\n",
    "# plt.show()\n",
    "# plt.imshow(x_train[2,:,:,1], aspect='auto', cmap='turbo')\n",
    "# plt.show()\n",
    "y_train = keras.utils.to_categorical(y_train - 6, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test -6 , num_classes)\n",
    "input_shape = (img_x, img_y, img_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 521ms/step - loss: 572.8930 - accuracy: 0.2604 - val_loss: 483.4688 - val_accuracy: 0.2083\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 4s 478ms/step - loss: 135.0417 - accuracy: 0.5833 - val_loss: 254.2366 - val_accuracy: 0.2917\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 4s 513ms/step - loss: 16.3045 - accuracy: 0.9062 - val_loss: 139.9712 - val_accuracy: 0.4583\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 4s 466ms/step - loss: 14.8379 - accuracy: 0.9271 - val_loss: 98.8976 - val_accuracy: 0.4167\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 4s 499ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 255.1499 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 4s 487ms/step - loss: 1.1578 - accuracy: 0.9896 - val_loss: 183.6643 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 4s 484ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 133.4041 - val_accuracy: 0.4583\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 4s 487ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 108.3212 - val_accuracy: 0.4583\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 4s 485ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 94.2242 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 4s 487ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 83.8219 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 4s 493ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 75.1990 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 7s 968ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 67.5543 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 60.5953 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 6s 806ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 54.3831 - val_accuracy: 0.5833\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 5s 631ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 48.6605 - val_accuracy: 0.5833\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 4s 508ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 43.5064 - val_accuracy: 0.6250\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 4s 487ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 39.8032 - val_accuracy: 0.6250\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 4s 475ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 36.3855 - val_accuracy: 0.6250\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 4s 466ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 33.1557 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.5747 - val_accuracy: 0.7083\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 28.4012 - val_accuracy: 0.7083\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 4s 468ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.3374 - val_accuracy: 0.7083\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 4s 463ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.8696 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 4s 467ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 23.5524 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 4s 469ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 22.3962 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 21.5926 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 4s 464ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 21.1912 - val_accuracy: 0.7917\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 4s 457ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 20.9736 - val_accuracy: 0.7917\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 4s 458ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 20.8118 - val_accuracy: 0.7917\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 4s 466ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 20.9973 - val_accuracy: 0.7917\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 21.1967 - val_accuracy: 0.7917\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 21.3899 - val_accuracy: 0.7917\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 4s 462ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 21.5808 - val_accuracy: 0.7917\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 4s 460ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 21.7680 - val_accuracy: 0.7917\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 4s 462ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 21.9467 - val_accuracy: 0.7917\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 4s 470ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 22.1194 - val_accuracy: 0.7917\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 4s 463ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 22.2838 - val_accuracy: 0.7917\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 4s 457ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 22.4388 - val_accuracy: 0.7917\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 22.5921 - val_accuracy: 0.7917\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 22.7341 - val_accuracy: 0.7917\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 22.8737 - val_accuracy: 0.7917\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 23.0018 - val_accuracy: 0.7917\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 23.1274 - val_accuracy: 0.7917\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 23.2789 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 4s 466ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 23.5208 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 4s 464ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 23.7671 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 4s 463ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.0001 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 4s 463ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.2180 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 4s 462ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.4173 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.6072 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 4s 466ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.7817 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 4s 459ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 24.9555 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 4s 459ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 25.1079 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 4s 460ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 25.2523 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 25.3837 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 4s 459ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 25.5118 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 25.6235 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 4s 463ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 25.7305 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 4s 462ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 25.8319 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 4s 462ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 25.9274 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 4s 458ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.0251 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.1058 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 4s 460ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.1864 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 4s 462ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.2566 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 4s 462ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.3244 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 4s 461ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.3881 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 4s 460ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.4531 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 4s 459ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.5072 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 4s 460ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.5520 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 4s 466ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.5874 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 4s 464ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.6224 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.6631 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 4s 479ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 26.7027 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "3/8 [==========>...................] - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\git\\Senior_Thesis\\CWT_Unicorn.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(num_classes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mcategorical_crossentropy, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m               optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49mepochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m           validation_data\u001b[39m=\u001b[39;49m(x_test, y_test), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[history])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer (I1)\n",
    "model.add(Input(shape=input_shape))\n",
    "\n",
    "# Convolution Layer (C2)\n",
    "model.add(Conv2D(8, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Convolution Layer (C3)\n",
    "model.add(Conv2D(16, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Flatten Layer (F4)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layer (D5)\n",
    "model.add(Dense(64))\n",
    "\n",
    "# Output Layer (O6)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adam(learning_rate= 0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, \n",
    "          epochs=epochs, verbose=1, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 1.4239 - accuracy: 0.2083 - val_loss: 1.4117 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.3922 - accuracy: 0.2812 - val_loss: 1.3924 - val_accuracy: 0.1667\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.3866 - accuracy: 0.2292 - val_loss: 1.3951 - val_accuracy: 0.2083\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.3565 - accuracy: 0.2604 - val_loss: 1.3802 - val_accuracy: 0.2917\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.3101 - accuracy: 0.3333 - val_loss: 1.5798 - val_accuracy: 0.1667\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.1766 - accuracy: 0.5104 - val_loss: 1.0649 - val_accuracy: 0.5417\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.1400 - accuracy: 0.4583 - val_loss: 1.0173 - val_accuracy: 0.5833\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.0119 - accuracy: 0.5417 - val_loss: 1.0698 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.0954 - accuracy: 0.5208 - val_loss: 1.0043 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.9731 - accuracy: 0.5729 - val_loss: 1.1624 - val_accuracy: 0.4583\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 1.0024 - accuracy: 0.5000 - val_loss: 0.9938 - val_accuracy: 0.4583\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.8877 - accuracy: 0.6354 - val_loss: 1.1124 - val_accuracy: 0.4167\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6999 - accuracy: 0.7083 - val_loss: 0.8591 - val_accuracy: 0.5833\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.6387 - accuracy: 0.6875 - val_loss: 1.0634 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4710 - accuracy: 0.8229 - val_loss: 0.9489 - val_accuracy: 0.5833\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4843 - accuracy: 0.7917 - val_loss: 1.0876 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.5109 - accuracy: 0.7708 - val_loss: 1.1259 - val_accuracy: 0.4167\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3325 - accuracy: 0.8646 - val_loss: 1.3111 - val_accuracy: 0.5833\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3246 - accuracy: 0.8438 - val_loss: 0.9044 - val_accuracy: 0.5833\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2061 - accuracy: 0.9167 - val_loss: 0.8568 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1356 - accuracy: 0.9479 - val_loss: 0.8443 - val_accuracy: 0.6250\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1135 - accuracy: 0.9792 - val_loss: 1.5803 - val_accuracy: 0.5417\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1026 - accuracy: 0.9583 - val_loss: 1.7998 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.1240 - accuracy: 0.9479 - val_loss: 1.3388 - val_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0875 - accuracy: 0.9688 - val_loss: 0.9100 - val_accuracy: 0.6250\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 1.3343 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0249 - accuracy: 0.9896 - val_loss: 1.6702 - val_accuracy: 0.5833\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0158 - accuracy: 0.9896 - val_loss: 1.5905 - val_accuracy: 0.6250\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.0056 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.8251 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5736 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7246 - val_accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 4.5211e-04 - accuracy: 1.0000 - val_loss: 1.9342 - val_accuracy: 0.5417\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 3.5194e-04 - accuracy: 1.0000 - val_loss: 2.0997 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 5.0769e-04 - accuracy: 1.0000 - val_loss: 2.1309 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 4.4906e-04 - accuracy: 1.0000 - val_loss: 2.0647 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 7.4725e-04 - accuracy: 1.0000 - val_loss: 1.9811 - val_accuracy: 0.5417\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 4.8674e-04 - accuracy: 1.0000 - val_loss: 1.9506 - val_accuracy: 0.5417\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 1.5969e-04 - accuracy: 1.0000 - val_loss: 1.9444 - val_accuracy: 0.5417\n",
      "Epoch 40/100\n",
      "4/8 [==============>...............] - ETA: 7s - loss: 3.6456e-04 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\git\\Senior_Thesis\\CWT_Unicorn.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(num_classes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X24sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mcategorical_crossentropy, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X24sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m               optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m \u001b[39m0.0001\u001b[39m), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X24sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X24sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X24sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49mepochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X24sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m           validation_data\u001b[39m=\u001b[39;49m(x_test, y_test), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/Senior_Thesis/CWT_Unicorn.ipynb#X24sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[history])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# # Layer 1: Convolutional + Max-Pooling\n",
    "# model.add(Conv2D(filters= 96, kernel_size= (11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "# # Layer 2: Convolutional + Max-Pooling\n",
    "# model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1) ,activation='relu', padding= 'valid'))\n",
    "# model.add(MaxPooling2D((3, 3), strides=(2, 2), padding= 'valid'))\n",
    "\n",
    "# # Layer 3: Convolutional\n",
    "# model.add(Conv2D(filters =384, kernel_size= (3, 3), strides=(1,1),activation='relu', padding= 'valid'))\n",
    "\n",
    "# # Layer 4: Convolutional\n",
    "# model.add(Conv2D(filters = 384, kernel_size= (3, 3), strides=(1,1),activation='relu', padding= 'valid'))\n",
    "\n",
    "# # Layer 5: Convolutional + Max-Pooling\n",
    "# model.add(Conv2D(filters = 256, kernel_size= (3, 3), strides=(1,1),activation='relu', padding= 'valid'))\n",
    "# model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# # Flatten the output for fully connected layers\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Layer 6: Fully Connected (Dense)\n",
    "# model.add(Dense(4096, activation='relu', input_shape = (13,13,128)))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "# # Layer 7: Fully Connected (Dense)\n",
    "# model.add(Dense(2048, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "# # Layer 8: Output Layer\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "#               optimizer=keras.optimizers.Adam(learning_rate= 0.0001), \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train, batch_size=batch_size, \n",
    "#           epochs=epochs, verbose=1, \n",
    "#           validation_data=(x_test, y_test), \n",
    "#           callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0, Train accuracy: 1.0\n",
      "Test loss: 76.14993286132812, Test accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy: {}'.format(test_score[0], test_score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
